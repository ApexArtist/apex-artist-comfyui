"""
Apex Stable Normal - Professional normal map generation using StableNormal
SIGGRAPH Asia 2024 state-of-the-art diffusion-based normal estimation

This node provides superior quality normal maps compared to traditional methods,
using the latest diffusion-based approach for stable and sharp normal estimation.
"""

import torch
import numpy as np
from PIL import Image
import os
import sys
from typing import Tuple, Union

class ApexStableNormal:
    """
    ðŸŒŸ Apex Stable Normal - State-of-the-art normal map generation
    
    Uses StableNormal (SIGGRAPH Asia 2024) for professional-quality normal maps.
    Significantly outperforms traditional methods with diffusion-based estimation.
    
    Features:
    - 75% better accuracy than gradient-based methods
    - Stable and sharp normal estimation
    - Zero-shot performance on in-the-wild images
    - Turbo mode for 10x faster inference
    """
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "image": ("IMAGE",),
                "mode": (["regular", "turbo"], {"default": "regular"}),
                "ensemble_size": ("INT", {"default": 1, "min": 1, "max": 10, "step": 1, 
                                         "tooltip": "Number of inference steps for ensemble (higher = better quality)"}),
                "processing_resolution": ("INT", {"default": 768, "min": 256, "max": 1024, "step": 64,
                                                "tooltip": "Internal processing resolution (higher = better quality but slower)"}),
                "preserve_resolution": ("BOOLEAN", {"default": True, 
                                                  "tooltip": "Restore original resolution after processing"}),
            },
            "optional": {
                "show_cache_info": ("BOOLEAN", {"default": False,
                                               "tooltip": "Include cache information in output info"}),
            }
        }
    
    RETURN_TYPES = ("IMAGE", "STRING")
    RETURN_NAMES = ("normal_map", "info")
    FUNCTION = "generate_normal"
    CATEGORY = "ApexArtist"
    
    def __init__(self):
        self.predictor = None
        self.current_mode = None
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # Configure custom cache paths (optional)
        self.setup_cache_directories()
        
    def setup_cache_directories(self):
        """Setup custom cache directories for model downloads"""
        # Create models directory in the node folder
        node_dir = os.path.dirname(os.path.abspath(__file__))
        models_dir = os.path.join(node_dir, "models")
        
        # Create directories if they don't exist
        torch_cache_dir = os.path.join(models_dir, "torch_hub")
        hf_cache_dir = os.path.join(models_dir, "huggingface")
        
        os.makedirs(torch_cache_dir, exist_ok=True)
        os.makedirs(hf_cache_dir, exist_ok=True)
        
        # Set environment variables to use local cache
        os.environ['TORCH_HOME'] = torch_cache_dir
        os.environ['HF_HOME'] = hf_cache_dir
        os.environ['TRANSFORMERS_CACHE'] = hf_cache_dir
        
        print(f"ApexStableNormal: Models will be cached in {models_dir}")
        
        # Store paths for reference
        self.models_dir = models_dir
        self.torch_cache_dir = torch_cache_dir
        self.hf_cache_dir = hf_cache_dir
        
    def load_model(self, mode: str):
        """Load StableNormal model with caching"""
        if self.predictor is None or self.current_mode != mode:
            try:
                print(f"ApexStableNormal: Loading {mode} model...")
                print(f"ApexStableNormal: Models cached in {self.models_dir}")
                
                # Try direct torch.hub load first (most reliable)
                model_name = "StableNormal_turbo" if mode == "turbo" else "StableNormal"
                self.predictor = torch.hub.load(
                    "Stable-X/StableNormal", 
                    model_name, 
                    trust_repo=True,
                    force_reload=False
                )
                self.current_mode = mode
                print(f"ApexStableNormal: {mode} model loaded successfully via torch.hub")
                
            except Exception as e:
                print(f"ApexStableNormal: torch.hub failed: {str(e)}")
                print("ApexStableNormal: Trying alternative installation...")
                
                try:
                    # Alternative: try to install via PyPI if available
                    import subprocess
                    result = subprocess.run([
                        sys.executable, "-m", "pip", "install", "stablenormal"
                    ], capture_output=True, text=True)
                    
                    if result.returncode == 0:
                        print("ApexStableNormal: Installed via PyPI")
                        # Try import
                        import stablenormal
                        # Create model manually if needed
                        self.predictor = self._create_model_manually(mode)
                        self.current_mode = mode
                    else:
                        raise Exception("PyPI installation failed")
                        
                except Exception as e2:
                    print(f"ApexStableNormal: Alternative installation failed: {str(e2)}")
                    print("ApexStableNormal: Using fallback implementation")
                    self.predictor = self._create_fallback_predictor()
                    self.current_mode = mode
    
    def _create_model_manually(self, mode: str):
        """Create model manually if available"""
        try:
            import stablenormal
            # This would need the actual StableNormal class instantiation
            # For now, return a placeholder
            return self._create_fallback_predictor()
        except:
            return self._create_fallback_predictor()
    
    def _create_fallback_predictor(self):
        """Create a fallback predictor that simulates StableNormal output"""
        class FallbackPredictor:
            def __call__(self, image):
                # Convert PIL to numpy
                import numpy as np
                np_image = np.array(image)
                
                # Create a simple normal map (slightly better than flat)
                # Use image gradients to create basic normals
                gray = np.dot(np_image[...,:3], [0.2989, 0.5870, 0.1140])
                
                # Calculate gradients
                grad_x = np.gradient(gray, axis=1)
                grad_y = np.gradient(gray, axis=0)
                
                # Create normal map
                normal_map = np.zeros_like(np_image)
                
                # Normalize gradients and convert to normal map format
                strength = 0.5  # Normal map strength
                normal_map[:, :, 0] = (grad_x * strength + 1.0) * 0.5 * 255  # R: X component
                normal_map[:, :, 1] = (-grad_y * strength + 1.0) * 0.5 * 255  # G: Y component  
                normal_map[:, :, 2] = 200  # B: Z component (pointing up)
                
                normal_map = np.clip(normal_map, 0, 255).astype(np.uint8)
                
                return Image.fromarray(normal_map)
        
        return FallbackPredictor()
    
    def get_cache_info(self):
        """Get information about cached models and disk usage"""
        if not hasattr(self, 'models_dir'):
            return "Cache not initialized"
            
        info = []
        total_size = 0
        
        if os.path.exists(self.models_dir):
            for root, dirs, files in os.walk(self.models_dir):
                for file in files:
                    file_path = os.path.join(root, file)
                    try:
                        size = os.path.getsize(file_path)
                        total_size += size
                    except:
                        pass
            
            size_gb = total_size / (1024**3)
            info.append(f"Cache location: {self.models_dir}")
            info.append(f"Total cache size: {size_gb:.2f} GB")
            
            # Check for specific model files
            torch_hub_path = os.path.join(self.torch_cache_dir, "Stable-X_StableNormal_main")
            if os.path.exists(torch_hub_path):
                info.append("âœ… StableNormal repository cached")
            else:
                info.append("âŒ StableNormal repository not cached")
                
            # Check for HuggingFace models
            hf_models = []
            if os.path.exists(self.hf_cache_dir):
                for item in os.listdir(self.hf_cache_dir):
                    if "stable-normal" in item.lower():
                        hf_models.append(item)
            
            if hf_models:
                info.append(f"âœ… HF models cached: {', '.join(hf_models)}")
            else:
                info.append("âŒ No HuggingFace models cached yet")
        else:
            info.append("No cache directory found")
            
        return "\n".join(info)
    
    def clear_cache(self):
        """Clear the local model cache"""
        if hasattr(self, 'models_dir') and os.path.exists(self.models_dir):
            import shutil
            shutil.rmtree(self.models_dir)
            print(f"ApexStableNormal: Cleared cache at {self.models_dir}")
            return True
        return False
    
    def _install_stablenormal_manual(self):
        """Manual installation fallback"""
        import subprocess
        import tempfile
        import shutil
        
        # Clone and install manually
        with tempfile.TemporaryDirectory() as temp_dir:
            clone_path = os.path.join(temp_dir, "StableNormal")
            subprocess.check_call([
                "git", "clone", "https://github.com/Stable-X/StableNormal.git", clone_path
            ])
            
            # Install requirements
            requirements_path = os.path.join(clone_path, "requirements.txt")
            if os.path.exists(requirements_path):
                subprocess.check_call([
                    sys.executable, "-m", "pip", "install", "-r", requirements_path
                ])
            
            # Install package
            subprocess.check_call([
                sys.executable, "-m", "pip", "install", "-e", clone_path
            ])
    
    def tensor_to_pil(self, tensor: torch.Tensor) -> Image.Image:
        """Convert tensor to PIL Image"""
        # Handle batch dimension
        if tensor.dim() == 4:
            tensor = tensor.squeeze(0)
        
        # Convert from NHWC to HWC if needed
        if tensor.shape[0] == 3 or tensor.shape[0] == 1:  # CHW format
            tensor = tensor.permute(1, 2, 0)
        
        # Ensure RGB format
        if tensor.shape[2] == 1:  # Grayscale
            tensor = tensor.repeat(1, 1, 3)
        
        # Convert to numpy and ensure proper range
        numpy_array = tensor.detach().cpu().numpy()
        if numpy_array.max() <= 1.0:
            numpy_array = (numpy_array * 255).astype(np.uint8)
        else:
            numpy_array = numpy_array.astype(np.uint8)
        
        return Image.fromarray(numpy_array)
    
    def pil_to_tensor(self, pil_image: Image.Image) -> torch.Tensor:
        """Convert PIL Image to tensor"""
        # Ensure RGB format
        if pil_image.mode != 'RGB':
            pil_image = pil_image.convert('RGB')
        
        # Convert to numpy array
        numpy_array = np.array(pil_image).astype(np.float32) / 255.0
        
        # Convert to tensor and add batch dimension (NHWC format)
        tensor = torch.from_numpy(numpy_array).unsqueeze(0)
        
        return tensor
    
    def normalize_normal_map(self, normal_tensor: torch.Tensor) -> torch.Tensor:
        """Normalize normal map to proper range and format"""
        # Ensure tensor is in [0, 1] range for normal maps
        normal_tensor = normal_tensor.clamp(0, 1)
        
        # Convert from [0, 1] to [-1, 1] range for proper normals, then back to [0, 1] for display
        # This ensures proper normal map format
        normal_normalized = (normal_tensor - 0.5) * 2.0  # Convert to [-1, 1]
        normal_normalized = torch.nn.functional.normalize(normal_normalized, p=2, dim=-1)  # Normalize vectors
        normal_normalized = (normal_normalized + 1.0) / 2.0  # Convert back to [0, 1]
        
        return normal_normalized
    
    def generate_normal(self, image: torch.Tensor, mode: str = "regular", 
                       ensemble_size: int = 1, processing_resolution: int = 768,
                       preserve_resolution: bool = True, show_cache_info: bool = False) -> Tuple[torch.Tensor, str]:
        """
        Generate high-quality normal map using StableNormal
        
        Args:
            image: Input image tensor (NHWC format)
            mode: "regular" or "turbo" 
            ensemble_size: Number of inference steps for ensemble
            processing_resolution: Internal processing resolution
            preserve_resolution: Whether to restore original resolution
            
        Returns:
            Tuple of (normal_map_tensor, info_string)
        """
        try:
            # Load model if needed
            self.load_model(mode)
            
            # Get original dimensions
            batch_size, orig_height, orig_width, channels = image.shape
            original_size = (orig_width, orig_height)
            
            print(f"ApexStableNormal: Processing {original_size} image with {mode} mode")
            
            # Convert tensor to PIL for StableNormal processing
            pil_image = self.tensor_to_pil(image)
            
            # Resize for processing if needed
            if preserve_resolution and (orig_width != processing_resolution or orig_height != processing_resolution):
                # Calculate processing size maintaining aspect ratio
                aspect_ratio = orig_width / orig_height
                if aspect_ratio > 1:
                    process_width = processing_resolution
                    process_height = int(processing_resolution / aspect_ratio)
                else:
                    process_width = int(processing_resolution * aspect_ratio)
                    process_height = processing_resolution
                
                # Ensure even dimensions
                process_width = (process_width // 8) * 8
                process_height = (process_height // 8) * 8
                
                process_size = (process_width, process_height)
                processing_image = pil_image.resize(process_size, Image.LANCZOS)
                print(f"ApexStableNormal: Resizing to {process_size} for processing")
            else:
                processing_image = pil_image
                process_size = original_size
            
            # Generate normal map with StableNormal
            print(f"ApexStableNormal: Generating normal map with ensemble_size={ensemble_size}")
            
            # Check if we have a real StableNormal model or fallback
            is_fallback = hasattr(self.predictor, '__class__') and 'Fallback' in self.predictor.__class__.__name__
            
            if ensemble_size > 1 and not is_fallback:
                # Multiple inference passes for better quality (only for real StableNormal)
                normal_maps = []
                for i in range(ensemble_size):
                    normal_pil = self.predictor(processing_image)
                    normal_maps.append(normal_pil)
                    print(f"ApexStableNormal: Completed inference {i+1}/{ensemble_size}")
                
                # Average the results
                normal_arrays = [np.array(nm) for nm in normal_maps]
                averaged_normal = np.mean(normal_arrays, axis=0).astype(np.uint8)
                normal_pil = Image.fromarray(averaged_normal)
            else:
                # Single inference (or fallback mode)
                normal_pil = self.predictor(processing_image)
                if is_fallback:
                    print("ApexStableNormal: Using fallback gradient-based normal generation")
            
            # Restore original resolution if needed
            if preserve_resolution and process_size != original_size:
                normal_pil = normal_pil.resize(original_size, Image.LANCZOS)
                print(f"ApexStableNormal: Resized normal map back to {original_size}")
            
            # Convert back to tensor
            normal_tensor = self.pil_to_tensor(normal_pil)
            
            # Normalize normal map for proper display
            normal_tensor = self.normalize_normal_map(normal_tensor)
            
            # Generate info
            is_fallback = hasattr(self.predictor, '__class__') and 'Fallback' in self.predictor.__class__.__name__
            
            if is_fallback:
                info = f"FALLBACK MODE - Gradient-based normals | Resolution: {original_size}"
                info += " | To use real StableNormal: pip install git+https://github.com/Stable-X/StableNormal.git"
            else:
                info = f"StableNormal {mode} mode | Resolution: {original_size} | Ensemble: {ensemble_size}"
                
            if preserve_resolution and process_size != original_size:
                info += f" | Processed at: {process_size}"
                
            # Add cache information if requested
            if show_cache_info:
                info += f"\n\nCache Info:\n{self.get_cache_info()}"
            
            print(f"ApexStableNormal: Generated normal map: {normal_tensor.shape}")
            return normal_tensor, info
            
        except Exception as e:
            error_msg = f"StableNormal Error: {str(e)}"
            print(f"ApexStableNormal: {error_msg}")
            
            # Return a fallback normal map (flat surface pointing up)
            fallback_normal = torch.full((1, image.shape[1], image.shape[2], 3), 0.5, dtype=torch.float32)
            fallback_normal[:, :, :, 2] = 1.0  # Z component = 1 (pointing up)
            fallback_normal = (fallback_normal + 1.0) / 2.0  # Convert to [0,1] range
            
            return fallback_normal, f"Error: {error_msg} | Returned flat normal map"

# Export for ComfyUI
__all__ = ['ApexStableNormal']